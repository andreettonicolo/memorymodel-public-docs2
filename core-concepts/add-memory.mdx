---
title: "Add Memory"
description: "Ingest unstructured data into the Memory Cluster."
---

## Operational Pipeline

#### The ingestion API operates on an **asynchronous, event-driven model**.\\

Requests are validated and acknowledged immediately (202 Accepted), then offloaded to a background worker queue. The data undergoes a specific transformation sequence before becoming searchable:

1. **Shift-Left Temporal Resolution:** The pipeline scans source.content for relative time references (e.g., "next Friday", "in three days"). These are resolved into absolute ISO 8601 timestamps _at the moment of ingestion_, creating a deterministic temporal index.
2. **Semantic Enrichment:** The system applies bidirectional expansion, injecting implicit context (themes, synonyms) to maximize vector overlap.
3. **Dual-Write Persistence:** Data is synchronously committed to both the Metadata Store and Vector Database.
4. **Centroid Calibration:** Finally, the user's semantic centroid is recalculated to reflect the new memory distribution, influencing future adaptive search modes.

<Frame>
  <img
    src="/images/diagrams/memory_ingestion.webp"
    alt="Memory ingestion pipeline"
    style={{ borderRadius:"0.5rem",width:"100%",backgroundColor:"#ffffff",padding:"0.5rem" }}
  />
</Frame>

## Text ingest (API)

Submit a text-based memory payload.

#### Payload schema (text)

| Field            | Type   | Status   | Description                                                                                            |
| ---------------- | ------ | -------- | ------------------------------------------------------------------------------------------------------ |
| `source.type`    | String | REQUIRED | Must be `text`.                                                                                        |
| `source.content` | String | REQUIRED | The raw text to ingest. This field is parsed for automatic relative date resolution (Shift-Left).      |
| `userContext`    | String | OPTIONAL | Additional meta-context (e.g., "Slack Message", "Email from CEO") used to guide the enrichment engine. |

<CodeGroup>

```bash cURL
curl -X POST "https://api.memorymodel.dev/v1/ingest" \
  -H "Content-Type: application/json" \
  -H "x-memory-cluster-access-key: sk_live_..." \
  -H "x-end-user-id: user_123" \
  -d '{
    "source": {
      "type": "text",
      "content": "The project deadline has been moved to next Friday."
    },
    "userContext": "Slack message from Project Manager"
  }'
```


```typescript TypeScript
// npm install @memorymodel/client
import { MemoryClient } from '@memorymodel/client';

const client = new MemoryClient({
  apiKey: "sk_live_...",
  defaultEndUserId: "user_123"
});

await client.add("The project deadline has been moved to next Friday.", {
  userContext: "Slack message from Project Manager"
});
```


```python Python
# pip install memory-model
from memorymodel import MemoryClient

client = MemoryClient(
    api_key="sk_live_...",
    default_end_user_id="user_123"
)

response = client.add("The project deadline has been moved to next Friday.", user_context="Slack message from Project Manager")
print(response.job_id)
```

</CodeGroup>

<Tip>
  Include `x-end-user-id` to track the end-user identity. This header is required in multi‑user setups; if your cluster is single‑user, you can use a simple identifier like `user_123`.
</Tip>

**Response (text)**

```json
{
  "status": "Accepted",
  "jobId": "job_1700000000000_user_123"
}
```

## Image ingest (API)

Submit an image for multimodal processing. The system extracts visual features and semantic context, integrating them into the memory graph alongside text nodes.

#### Payload schema (image)

| Field         | Type   | Status   | Description                                                               |
| ------------- | ------ | -------- | ------------------------------------------------------------------------- |
| `imageData`   | String | REQUIRED | Base64-encoded image string.                                              |
| `userContext` | String | OPTIONAL | Context to anchor the visual analysis (e.g., "Screenshot of error logs"). |

<CodeGroup>

```bash cURL
curl -X POST "https://api.memorymodel.dev/v1/ingest/image"  \
  -H "Content-Type: application/json" \
  -H "x-memory-cluster-access-key: sk_live_..." \
  -H "x-end-user-id: user_123" \
  -d '{
    "imageData": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII=",
    "userContext": "Screenshot of the error message"
  }'
```


```typescript TypeScript
// npm install @memorymodel/client
await client.addImage("iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII=", {
  userContext: "Screenshot of the error message"
});
```


```python Python
# pip install memory-model
import base64
from memorymodel import MemoryClient

# client = MemoryClient(...)

# Assuming you have the image file
# with open("screenshot.png", "rb") as f:
#     img_b64 = base64.b64encode(f.read()).decode()

img_b64 = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="
response = client.add_image(img_b64, user_context="Screenshot of the error message")
```

</CodeGroup>

<Note>
  For large images, ensure your client supports large payloads. The `imageData` field must be a valid Base64 string (with or without the data URI prefix).
</Note>

**Response (image)**

```json
{
  "status": "Accepted",
  "jobId": "img_job_1700000000000_user_123",
  "previewUrl": "https://storage.googleapis.com/..."
}
```

<Warning>
  The `previewUrl` must point to a valid storage bucket and object. Invalid bucket names will return an error from the storage provider.
</Warning>